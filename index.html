<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="PureACL: View Consistent Purification for Accurate Cross-View Localization">
  <meta name="keywords" content="PureACL">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta property="og:title" content="PureACL: View Consistent Purification for Accurate Cross-View Localization" />
  <meta property="og:description" content="PureACL: View Consistent Purification for Accurate Cross-View Localization" />
  <meta property="og:image" content="https://ShanWang-Shan.github.io/megane/static/images/teaser.jpg" />
  <title>PureACL: View Consistent Purification for Accurate Cross-View Localization</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-T834G2HR2M"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-T834G2HR2M');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">PureACL: View Consistent Purification for Accurate Cross-View Localization</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https:/ShanWang-Shan.github.io">Shan Wang</a>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=9W32tDUAAAAJ&hl=en">Yanhao Zhang</a>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=wPNd0xkAAAAJ&hl=en">Akhil Perincherry</a>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=EUS0qnEAAAAJ&hl=en">Ankit Vora</a>,</span>
            <span class="author-block">
              <a href="http://users.cecs.anu.edu.au/~hongdong/">Hongdong Li</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Australian National University,</span>
            <span class="author-block">CSIRO, </span>
            <span class="author-block">Ford Motor Company</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">ICCV 2023</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2308.08110"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/ShanWang-Shan/PureACL.git"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="visualization" autoplay muted loop playsinline height="100%">
        <source src="./static/images/PureACL.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">PureACL</span> Confidence and pose optimization visualization.
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method Overview</h2>
        <div class="content has-text-justified">
        <p>
          SAFCE is used to produce feature maps (F), view-consistent confidence maps (V), and on-ground confidence maps (O) separately for satellite and ground-view images. The VOKD fuses the confidence maps and identifies the top-k confident features from the ground-view images and their corresponding features on the satellite feature maps. Sub-pixel interpolation is used to lookup point features (F[p] from F) and their weights (w[p] from VxO). The residual between the two views and the point weights are fed to the RPRB for subsequent pose optimization. The olive outline indicates that the O^s disables gradient backpropagation while red, green, blue and magenta outlines and points represent the front, left, right and rear views, respectively.
        </p>
        </div>
        <div class="publication-video">
          <img src="./static/images/PureACL.png" alt="Teaser" style="width:100%;">
        </div>
      </div>
    </div>
    <!--/ Paper video. -->


    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            This paper proposes a fine-grained self-localization method for outdoor robotics that utilizes a flexible number of onboard cameras and readily accessible satellite images. The proposed method addresses limitations in existing cross-view localization methods that struggle to handle noise sources such as moving objects and seasonal variations. It is the first sparse visual-only method that enhances perception in dynamic environments by detecting view-consistent key points and their corresponding deep features from ground and satellite views, while removing off-the-ground objects and establishing homography transformation between the two views. Moreover, the proposed method incorporates a spatial embedding approach that leverages camera intrinsic and extrinsic information to reduce the ambiguity of purely visual matching, leading to improved feature matching and overall pose estimation accuracy. The method exhibits strong generalization and is robust to environmental changes, requiring only geo-poses as ground truth. Extensive experiments on the KITTI and Ford Multi-AV Seasonal datasets demonstrate that our proposed method outperforms existing state-of-the-art methods, achieving median spatial accuracy errors below 0.5 meters along the lateral and longitudinal directions, and a median orientation accuracy error below 2 degrees.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->


    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Comparison on the KITTI-CVL dataset</h2>
        <div class="content has-text-justified">
        </div>
        <div class="publication-video">
          <img src="./static/images/comparison_kitti.png" alt="Teaser" style="width:100%;">
        </div>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Comparison on the FordAV-CVL dataset</h2>
        <div class="content has-text-justified">
        </div>
        <div class="publication-video">
          <img src="./static/images/comparison_ford.png" alt="Teaser" style="width:100%;">
        </div>
      </div>
    </div>

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{wang2023view,
      title={View Consistent Purification for Accurate Cross-View Localization}, 
      author={Shan Wang and Yanhao Zhang and Akhil Perincherry and Ankit Vora and Hongdong Li},
      year={2023},
      eprint={2308.08110},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
   }</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://arxiv.org/abs/2308.08110">
        <i class="fas fa-file-pdf"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <!-- <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p> -->
          <p>
            This website borrows the template from <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
